{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vectorize\n",
    "Vectorizing Scratch projects encoded in syntax-based language (using `scratch-textify`), **using the command line utility for `fasttext`**. Output is **word embeddings** (not project embeddings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### settings and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executed by system command line\n",
    "!pip3 install -q fasttext\n",
    "!pip3 install -q gensim\n",
    "!pip3 install -q scikit-learn\n",
    "!pip3 install -q pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import fasttext\n",
    "import gensim\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"./dataset\"\n",
    "TRAIN_TARGET = os.path.abspath(os.path.join(DATASET, 'train')) # add the .txt later.\n",
    "\n",
    "MODEL = \"./model\"\n",
    "MODEL_TARGET = os.path.abspath(os.path.join(MODEL, 'vectorization')) # add the .bin later.\n",
    "\n",
    "FASTTEXT = \"./fastText-0.9.1\"\n",
    "FASTTEXT_TARGET = os.path.join(FASTTEXT, 'fasttext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/labdalla/Documents/Scratch MEng/Workspace/supervised-learning/scratch-vectorize\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train on 1000 samples\n",
    "Vectorize the dataset using fasttext. The end product are \"embeddings\" for blocks / symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/labdalla/Documents/Scratch MEng/Workspace/supervised-learning/scratch-vectorize/dataset/train_1000.txt\n",
      "/Users/labdalla/Documents/Scratch MEng/Workspace/supervised-learning/scratch-vectorize/dataset/train_1000.ids\n",
      "/Users/labdalla/Documents/Scratch MEng/Workspace/supervised-learning/scratch-vectorize/model/vectorization_1000.bin\n"
     ]
    }
   ],
   "source": [
    "train_target = TRAIN_TARGET + \"_\" + str(NUM_SAMPLES) + \".txt\"\n",
    "train_ids_target = TRAIN_TARGET + \"_\" + str(NUM_SAMPLES) + \".ids\"\n",
    "model_target = MODEL_TARGET + \"_\" + str(NUM_SAMPLES) + \".bin\"\n",
    "\n",
    "print(train_target)\n",
    "print(train_ids_target)\n",
    "print(model_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TARGET = train_target\n",
    "OUTPUT_TARGET = MODEL_TARGET \n",
    "MINCOUNT = 5\n",
    "DIM = 128\n",
    "MINN = 3\n",
    "MAXN = 6\n",
    "EPOCH = 5\n",
    "LR = 0.05\n",
    "\n",
    "skipgram = \" skipgram -input INPUT_TARGET -minCount MINCOUNT -dim DIM -minn MINN -maxn MAXN -epoch EPOCH -lr LR -output OUTPUT_TARGET\"\n",
    "\n",
    "# model = fasttext.train_unsupervised(train_target,\n",
    "#                                     model = \"skipgram\",\n",
    "#                                     minCount = 5,\n",
    "#                                     dim=128,         # number of dimensions\n",
    "#                                     minn=3,          # minimum size of subword n-grams\n",
    "#                                     maxn=6,          # maximum size of subword n-grams\n",
    "#                                     epoch = 5,       # number of training epochs\n",
    "#                                     lr = 0.05)       # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libc++abi.dylib: terminating with uncaught exception of type std::invalid_argument: stoi: no conversion\r\n"
     ]
    }
   ],
   "source": [
    "!{FASTTEXT_TARGET + skipgram}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_model(model_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train on 10,000 samples\n",
    "Vectorize the dataset using fasttext. The end product are \"embeddings\" for blocks / symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/shared/lena/dataset/train_10000.txt\n",
      "/home/jovyan/shared/lena/dataset/train_10000.ids\n",
      "/home/jovyan/shared/lena/model/vectorization_10000.bin\n"
     ]
    }
   ],
   "source": [
    "train_target = TRAIN_TARGET + \"_\" + str(NUM_SAMPLES) + \".txt\"\n",
    "train_ids_target = TRAIN_TARGET + \"_\" + str(NUM_SAMPLES) + \".ids\"\n",
    "model_target = MODEL_TARGET + \"_\" + str(NUM_SAMPLES) + \".bin\"\n",
    "\n",
    "print(train_target)\n",
    "print(train_ids_target)\n",
    "print(model_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_unsupervised(train_target,\n",
    "                                    model = \"skipgram\",\n",
    "                                    minCount = 5,\n",
    "                                    dim=128,         # number of dimensions\n",
    "                                    minn=3,          # minimum size of subword n-grams\n",
    "                                    maxn=6,          # maximum size of subword n-grams\n",
    "                                    epoch = 5,       # number of training epochs\n",
    "                                    lr = 0.05)       # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(model_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train on 100,000 samples\n",
    "Vectorize the dataset using fasttext. The end product are \"embeddings\" for blocks / symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/shared/lena/dataset/train_100000.txt\n",
      "/home/jovyan/shared/lena/dataset/train_100000.ids\n",
      "/home/jovyan/shared/lena/model/vectorization_100000.bin\n"
     ]
    }
   ],
   "source": [
    "train_target = TRAIN_TARGET + \"_\" + str(NUM_SAMPLES) + \".txt\"\n",
    "train_ids_target = TRAIN_TARGET + \"_\" + str(NUM_SAMPLES) + \".ids\"\n",
    "model_target = MODEL_TARGET + \"_\" + str(NUM_SAMPLES) + \".bin\"\n",
    "\n",
    "print(train_target)\n",
    "print(train_ids_target)\n",
    "print(model_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_unsupervised(train_target,\n",
    "                                    model = \"skipgram\",\n",
    "                                    minCount = 5,\n",
    "                                    dim=128,         # number of dimensions\n",
    "                                    minn=3,          # minimum size of subword n-grams\n",
    "                                    maxn=6,          # maximum size of subword n-grams\n",
    "                                    epoch = 5,       # number of training epochs\n",
    "                                    lr = 0.05)       # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(model_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train on 500,000 samples\n",
    "Vectorize the dataset using fasttext. The end product are \"embeddings\" for blocks / symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/shared/lena/dataset/train_500000.txt\n",
      "/home/jovyan/shared/lena/dataset/train_500000.ids\n",
      "/home/jovyan/shared/lena/model/vectorization_500000.bin\n"
     ]
    }
   ],
   "source": [
    "train_target = TRAIN_TARGET + \"_\" + str(NUM_SAMPLES) + \".txt\"\n",
    "train_ids_target = TRAIN_TARGET + \"_\" + str(NUM_SAMPLES) + \".ids\"\n",
    "model_target = MODEL_TARGET + \"_\" + str(NUM_SAMPLES) + \".bin\"\n",
    "\n",
    "print(train_target)\n",
    "print(train_ids_target)\n",
    "print(model_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_unsupervised(train_target,\n",
    "                                    model = \"skipgram\",\n",
    "                                    minCount = 5,\n",
    "                                    dim=128,         # number of dimensions\n",
    "                                    minn=3,          # minimum size of subword n-grams\n",
    "                                    maxn=6,          # maximum size of subword n-grams\n",
    "                                    epoch = 5,       # number of training epochs\n",
    "                                    lr = 0.05)       # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(model_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
