{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fasttext vectorize\n",
    "FASTTEXT Vectorizing Scratch projects encoded in syntax-based language (using `scratch-textify`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### settings and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Executed by system command line\n",
    "# !pwd\n",
    "!pip install -q fasttext\n",
    "!pip install -q gensim\n",
    "!pip install -q scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import fasttext\n",
    "import gensim\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"./dataset\"\n",
    "TRAIN_TARGET = os.path.abspath(os.path.join(DATASET, 'train')) # add the .txt later.\n",
    "\n",
    "MODEL = \"./model\"\n",
    "MODEL_TARGET = os.path.abspath(os.path.join(MODEL, 'vectorization')) # add the .bin later.\n",
    "\n",
    "NUM_SAMPLES = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectorize\n",
    "Vectorize the dataset using fasttext. The end product are \"embeddings\" for blocks / symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = TRAIN_TARGET + \"_\" + str(NUM_SAMPLES) + \".txt\"\n",
    "model_target = MODEL_TARGET + \"_\" + str(NUM_SAMPLES) + \".bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_unsupervised(train_target,\n",
    "                                    model = \"skipgram\",\n",
    "                                    minCount = 5,\n",
    "                                    wordNgrams=1,\n",
    "                                    dim=128,\n",
    "                                    minn=3,\n",
    "                                    maxn=6,\n",
    "                                    epoch = 5,\n",
    "                                    lr = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(model_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model\n",
    "Load the model into gensim for better evaluation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_model = gensim.models.fasttext.load_facebook_vectors(model_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('motion_turnleft', 0.8829981684684753),\n",
       " ('motion_movesteps', 0.6902536153793335),\n",
       " ('motion_pointindirection', 0.6546069383621216),\n",
       " ('motion_ifonedgebounce', 0.6008567214012146),\n",
       " ('motion_pointtowards', 0.5628019571304321),\n",
       " ('motion_direction', 0.5596492290496826),\n",
       " ('looks_changesizeby', 0.5229341387748718),\n",
       " ('motion_glideto', 0.5154552459716797),\n",
       " ('motion_setrotationstyle', 0.48891136050224304),\n",
       " ('pen_changePenHueBy', 0.4830555319786072)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.wv.most_similar(positive=[\"motion_turnright\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## project embeddings\n",
    "Combine word embeddings for all words in the project's text by averaging them. Resulting vector is the project embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>542</td>\n",
       "      <td>_STARTSTACK_ event_whenthisspriteclicked _NEXT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>492</td>\n",
       "      <td>_STARTSTACK_ event_whenkeypressed _MENU_ menu_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>649</td>\n",
       "      <td>_STARTSTACK_ event_whenflagclicked _NEXT_ cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>_STARTSTACK_ event_whenthisspriteclicked _NEXT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>_STARTSTACK_ event_whenflagclicked _NEXT_ cont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          project_text\n",
       "542  _STARTSTACK_ event_whenthisspriteclicked _NEXT...\n",
       "492  _STARTSTACK_ event_whenkeypressed _MENU_ menu_...\n",
       "649  _STARTSTACK_ event_whenflagclicked _NEXT_ cont...\n",
       "568  _STARTSTACK_ event_whenthisspriteclicked _NEXT...\n",
       "116  _STARTSTACK_ event_whenflagclicked _NEXT_ cont..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read in the projects text file into df\n",
    "def csv_to_df(filepath, columns=[]):\n",
    "    df = pd.read_csv(filepath, sep=\"\\n\", header=None)\n",
    "    df.columns = columns\n",
    "#     df = df.set_index('project_text')\n",
    "    return df\n",
    "\n",
    "df = csv_to_df(train_target, columns=['project_text'])\n",
    "print(df.shape)\n",
    "display(df.sample(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# apply to each row: the split function on the project text on space (\" \")\n",
    "tokens_df = df.apply(lambda row: row['project_text'].split(\" \"), axis=1)\n",
    "tokens_df = pd.DataFrame(tokens_df)\n",
    "tokens_df.columns = ['project_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:  1051\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens: \", len(tokens_df.iloc[100]['project_tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_word_embeddings(project_tokens):\n",
    "    # this function gets all word embeddings for tokens in a single project.\n",
    "    # apply the get_word_vector to each token in project.\n",
    "    return list(map(model.get_word_vector, project_tokens))\n",
    "    \n",
    "# map the get_word_vector function from fasttext to each token from split list above\n",
    "embeddings_df = tokens_df.apply(lambda row: get_batch_word_embeddings(row['project_tokens']), axis=1)\n",
    "embeddings_df = pd.DataFrame(embeddings_df)\n",
    "embeddings_df.columns = ['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[[0.21450824, -0.045012362, -0.13869916, 0.273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[[0.21450824, -0.045012362, -0.13869916, 0.273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[[0.21450824, -0.045012362, -0.13869916, 0.273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[[0.21450824, -0.045012362, -0.13869916, 0.273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[[0.21450824, -0.045012362, -0.13869916, 0.273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>[[0.21450824, -0.045012362, -0.13869916, 0.273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>[[0.21450824, -0.045012362, -0.13869916, 0.273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>[[0.21450824, -0.045012362, -0.13869916, 0.273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>[[0.21450824, -0.045012362, -0.13869916, 0.273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>[[0.21450824, -0.045012362, -0.13869916, 0.273...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            embeddings\n",
       "0    [[0.21450824, -0.045012362, -0.13869916, 0.273...\n",
       "1    [[0.21450824, -0.045012362, -0.13869916, 0.273...\n",
       "2    [[0.21450824, -0.045012362, -0.13869916, 0.273...\n",
       "3    [[0.21450824, -0.045012362, -0.13869916, 0.273...\n",
       "4    [[0.21450824, -0.045012362, -0.13869916, 0.273...\n",
       "..                                                 ...\n",
       "995  [[0.21450824, -0.045012362, -0.13869916, 0.273...\n",
       "996  [[0.21450824, -0.045012362, -0.13869916, 0.273...\n",
       "997  [[0.21450824, -0.045012362, -0.13869916, 0.273...\n",
       "998  [[0.21450824, -0.045012362, -0.13869916, 0.273...\n",
       "999  [[0.21450824, -0.045012362, -0.13869916, 0.273...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_df = embeddings_df.apply(lambda row: np.array(row['embeddings']), axis=1)\n",
    "embeddings_df = pd.DataFrame(embeddings_df)\n",
    "embeddings_df.columns = ['embeddings']\n",
    "display(embeddings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1051, 128)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_df.iloc[100]['embeddings'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[0.023995442, 0.022763226, 0.0007133481, 0.036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[-0.016639246, -0.0019163504, -0.0150304735, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[-0.05557948, -0.018262913, -0.03116151, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[0.04061277, 0.031710193, -0.006383933, 0.0316...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[0.047298573, -0.009121757, -0.043928746, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>[-0.030901695, -0.03857236, -0.032687176, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>[0.06905353, 0.053826157, -0.0106923, 0.042574...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>[0.06646415, -0.020444186, 0.011007728, 0.0525...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>[0.08105424, 0.0006001053, -0.015349248, 0.066...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>[0.052408516, 0.008443745, -0.015590198, 0.032...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             embedding\n",
       "0    [0.023995442, 0.022763226, 0.0007133481, 0.036...\n",
       "1    [-0.016639246, -0.0019163504, -0.0150304735, -...\n",
       "2    [-0.05557948, -0.018262913, -0.03116151, -0.00...\n",
       "3    [0.04061277, 0.031710193, -0.006383933, 0.0316...\n",
       "4    [0.047298573, -0.009121757, -0.043928746, 0.06...\n",
       "..                                                 ...\n",
       "995  [-0.030901695, -0.03857236, -0.032687176, 0.02...\n",
       "996  [0.06905353, 0.053826157, -0.0106923, 0.042574...\n",
       "997  [0.06646415, -0.020444186, 0.011007728, 0.0525...\n",
       "998  [0.08105424, 0.0006001053, -0.015349248, 0.066...\n",
       "999  [0.052408516, 0.008443745, -0.015590198, 0.032...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take the mean of those vectors to get the project embedding\n",
    "project_embeddings = embeddings_df.apply(lambda row: np.mean(row['embeddings'], axis=0), axis=1)\n",
    "project_embeddings = pd.DataFrame(project_embeddings)\n",
    "project_embeddings.columns = ['embedding']\n",
    "display(project_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "print(project_embeddings.iloc[0]['embedding'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
